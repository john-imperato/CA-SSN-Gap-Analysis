---
title: "Prepare gap analysis data"
author: "John Imperato"
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 2
editor: visual
execute:
  echo: true
  warning: false
  message: false
---



```{r}
# scripts/01_load_ecoregions.R
# Load EPA Ecoregions (Level IV) and write a clean GeoPackage copy

# Load packages
suppressPackageStartupMessages({
  library(sf)
  library(dplyr)
  library(janitor)
})

# Set paths (using absolute path that works)
base_path <- "/Users/johnimperato/Desktop/CA-SSN/CA-SSN-Gap-Analysis"
shp_path <- file.path(base_path, "data", "EPA_ecoregions_CA", "ca_eco_l4", "ca_eco_l4.shp")
out_dir <- file.path(base_path, "data", "processed")
out_gpkg <- file.path(out_dir, "Ecoregions.gpkg")

# Create output directory if needed
dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)

# Read shapefile
eco <- st_read(shp_path, quiet = TRUE)

# Clean column names
eco <- clean_names(eco)

# Print summary
cat("EPA Level IV Ecoregions loaded:\n")
cat("  Features:", nrow(eco), "\n")
cat("  CRS:", st_crs(eco)$input, "\n")
cat("  Columns:", ncol(eco), "\n")

# Transform to WGS84
eco_wgs84 <- st_transform(eco, 4326)

# Write to GeoPackage
st_write(eco_wgs84, 
         out_gpkg,
         layer = "EPA_L4_CA", 
         delete_layer = TRUE, 
         quiet = TRUE)

cat("\nSaved to:", out_gpkg, "\n")
cat("  Layer: EPA_L4_CA\n")
cat("  CRS: WGS84 (EPSG:4326)\n")
```

```{r}

# Explore EPA Ecoregions GeoPackage

# Load packages
library(sf)
library(dplyr)
library(ggplot2)

# Set base path (same as before)
base_path <- "/Users/johnimperato/Desktop/CA-SSN/CA-SSN-Gap-Analysis"
gpkg_path <- file.path(base_path, "data", "processed", "Ecoregions.gpkg")

# Read the GeoPackage
eco <- st_read(gpkg_path, 
               layer = "EPA_L4_CA", 
               quiet = TRUE)

# Basic information
cat("=== BASIC INFORMATION ===\n")
cat("Features (rows):", nrow(eco), "\n")
cat("Variables (columns):", ncol(eco), "\n")
cat("Geometry type:", st_geometry_type(eco)[1], "\n")
cat("CRS:", st_crs(eco)$input, "\n")
cat("Bounding box:\n")
print(st_bbox(eco))

# Column names and types
cat("\n=== COLUMN STRUCTURE ===\n")
str(eco %>% st_drop_geometry())

# Preview first few rows (without geometry)
cat("\n=== FIRST 5 ROWS (without geometry) ===\n")
print(eco %>% 
      st_drop_geometry() %>% 
      head(5))

# Summary statistics for numeric columns
cat("\n=== NUMERIC COLUMN SUMMARY ===\n")
eco %>% 
  st_drop_geometry() %>% 
  select(where(is.numeric)) %>% 
  summary() %>% 
  print()

# Unique values in key categorical columns
cat("\n=== UNIQUE VALUES IN KEY COLUMNS ===\n")
cat("Unique Level 4 ecoregions:", n_distinct(eco$us_l4code), "\n")
cat("Unique Level 3 ecoregions:", n_distinct(eco$us_l3code), "\n")
cat("Unique Level 2 ecoregions:", n_distinct(eco$na_l2code), "\n")
cat("Unique Level 1 ecoregions:", n_distinct(eco$na_l1code), "\n")

# Most common Level 3 ecoregions
cat("\n=== TOP 10 LEVEL 3 ECOREGIONS BY POLYGON COUNT ===\n")
eco %>% 
  st_drop_geometry() %>% 
  count(us_l3name, sort = TRUE) %>% 
  head(10) %>% 
  print()

# Area calculations
cat("\n=== AREA STATISTICS ===\n")
eco_with_area <- eco %>%
  mutate(area_km2 = as.numeric(st_area(.) / 1e6))  # Convert to km²

cat("Total area:", format(sum(eco_with_area$area_km2), big.mark=","), "km²\n")
cat("Mean polygon area:", format(mean(eco_with_area$area_km2), big.mark=","), "km²\n")
cat("Median polygon area:", format(median(eco_with_area$area_km2), big.mark=","), "km²\n")
cat("Smallest polygon:", format(min(eco_with_area$area_km2), digits=2), "km²\n")
cat("Largest polygon:", format(max(eco_with_area$area_km2), big.mark=","), "km²\n")

# Simple visualization
cat("\n=== CREATING VISUALIZATION ===\n")
p <- ggplot(eco) +
  geom_sf(aes(fill = us_l3name), show.legend = FALSE) +
  theme_minimal() +
  labs(title = "EPA Level IV Ecoregions of California",
       subtitle = paste(nrow(eco), "polygons colored by Level 3 ecoregion")) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank())

print(p)

# Check for any potential data issues
cat("\n=== DATA QUALITY CHECKS ===\n")
cat("Missing values per column:\n")
eco %>% 
  st_drop_geometry() %>% 
  summarise(across(everything(), ~sum(is.na(.)))) %>% 
  tidyr::pivot_longer(everything(), names_to = "column", values_to = "missing") %>% 
  filter(missing > 0) %>% 
  {if(nrow(.) > 0) print(.) else cat("  No missing values found\n")}

# Check geometry validity
invalid_geoms <- sum(!st_is_valid(eco))
cat("\nInvalid geometries:", invalid_geoms, "\n")
if(invalid_geoms > 0) {
  cat("  Consider running: eco <- st_make_valid(eco)\n")
}

cat("\n=== EXPLORATION COMPLETE ===\n")

```

## 1. Load data

Load the processed Sentinel Sites and EPA ecoregions, clean field names, and align CRS so layers match.

```{r step-01-load, message=FALSE, warning=FALSE}

# Minimal, robust loader using the .here sentinel
for (p in c("here","sf","janitor")) if (!requireNamespace(p, quietly = TRUE)) install.packages(p)
library(here); library(sf); library(janitor)

sites_gpkg <- here::here("data","processed","SSN_All_Sites.gpkg")
eco_gpkg   <- here::here("data","processed","Ecoregions.gpkg")

sites <- st_read(sites_gpkg, layer = "SSN_All_Sites", quiet = TRUE) |> clean_names()
eco   <- st_read(eco_gpkg,   layer = "EPA_L4_CA",     quiet = TRUE) |> clean_names() |> st_make_valid()

if (!is.na(st_crs(sites)) && !is.na(st_crs(eco)) && st_crs(sites) != st_crs(eco)) {
  sites <- st_transform(sites, st_crs(eco))
}

```

## 2. Spatial join (Sentinel Sites × US EPA ecoregions)

Attach Level III and Level IV ecoregion attributes to each Sentinel Site using an intersects join.

### 2a. Perform join

```{r step-02a-spatial-join, message=FALSE, warning=FALSE}

# Step 2a — Spatial join (Sentinel Sites × EPA Level IV ecoregions)
library(dplyr); library(sf)

need <- c("us_l4code","us_l4name","l4_key","us_l3code","us_l3name","l3_key")
eco_keep <- if (all(need %in% names(eco))) dplyr::select(eco, dplyr::all_of(need)) else eco

sites_with_eco <- sf::st_join(
  x = sites,
  y = eco_keep,
  join = sf::st_intersects,
  left = TRUE,
  largest = TRUE
)

n_unmatched <- sum(is.na(sites_with_eco$us_l4code))
cat("Spatial join complete —", nrow(sites_with_eco), "sites processed;", n_unmatched, "unmatched.\n")

```

### 2b. Inspect joined data

```{r step-02b-inspect, message=FALSE, warning=FALSE}

# Step 2b — Inspect joined data (quick QA only)
library(dplyr); library(sf)

cat("Rows:", nrow(sites_with_eco), "| Columns:", ncol(sites_with_eco), "\n")
print(head(names(sites_with_eco), 15))

print(
  sites_with_eco |>
    sf::st_drop_geometry() |>
    dplyr::select(org, contains("l3"), contains("l4")) |>
    head(10)
)

eco_counts <- sites_with_eco |>
  sf::st_drop_geometry() |>
  dplyr::summarise(
    n_L3 = dplyr::n_distinct(us_l3code, na.rm = TRUE),
    n_L4 = dplyr::n_distinct(us_l4code, na.rm = TRUE)
  )
print(eco_counts)

n_unmatched <- sum(is.na(sites_with_eco$us_l4code))
cat("Unmatched sites (no L4):", n_unmatched, "\n")

```

### 2c. Save joined outputs

```{r step-02c-save-joined, message=FALSE, warning=FALSE}
# Step 3 — Save joined outputs (GeoPackage + lookup CSV)

gpkg_out   <- here::here("data","processed","SSN_Sites_with_Ecoregions.gpkg")
layer_name <- "SSN_Sites_with_Ecoregions"
tbl_dir    <- here::here("outputs","tables")
dir.create(tbl_dir, recursive = TRUE, showWarnings = FALSE)

if (file.exists(gpkg_out)) try(sf::st_delete(gpkg_out, layer = layer_name), silent = TRUE)
sf::st_write(sites_with_eco, gpkg_out, layer = layer_name, delete_layer = TRUE, quiet = TRUE)
cat("Wrote GeoPackage:", normalizePath(gpkg_out), "\n")

site_lookup <- sites_with_eco |>
  sf::st_drop_geometry() |>
  dplyr::select(site_id, site_name, org, us_l3code, us_l3name, us_l4code, us_l4name) |>
  dplyr::arrange(org, us_l3name, us_l4name)

csv_out <- file.path(tbl_dir, "Sites_with_Ecoregions.csv")
readr::write_csv(site_lookup, csv_out)
cat("Wrote lookup table:", normalizePath(csv_out), "\n")
```



